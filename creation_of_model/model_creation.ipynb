{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"563ecc68-58c0-4a44-a3bf-7dc24f352793"},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt"],"id":"563ecc68-58c0-4a44-a3bf-7dc24f352793"},{"cell_type":"code","execution_count":1,"metadata":{"id":"mna_OGeW7CIk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3635560b-4453-4dc0-c5f8-ccd61523c522","executionInfo":{"status":"ok","timestamp":1652053712361,"user_tz":-360,"elapsed":21102,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"mna_OGeW7CIk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7418a6f-ddf4-4d26-8684-067a6d3df08a"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/age_gender.csv\")"],"id":"f7418a6f-ddf4-4d26-8684-067a6d3df08a"},{"cell_type":"code","source":["df.ethnicity.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNp2Ls1yfuN9","executionInfo":{"status":"ok","timestamp":1652043055342,"user_tz":-360,"elapsed":32,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}},"outputId":"7d71ab52-5e5a-4e31-8cd7-17fca3b13481"},"id":"HNp2Ls1yfuN9","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    10078\n","1     4526\n","3     3975\n","2     3434\n","4     1692\n","Name: ethnicity, dtype: int64"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"0e37fb3f-ae25-4f5f-8554-6d48aa3a375b","outputId":"027f73a0-e754-4b73-ab8f-632354b6c4da","executionInfo":{"status":"ok","timestamp":1652043055343,"user_tz":-360,"elapsed":28,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       age  ethnicity  gender                        img_name  \\\n","0        1          2       0  20161219203650636.jpg.chip.jpg   \n","1        1          2       0  20161219222752047.jpg.chip.jpg   \n","2        1          2       0  20161219222832191.jpg.chip.jpg   \n","3        1          2       0  20161220144911423.jpg.chip.jpg   \n","4        1          2       0  20161220144914327.jpg.chip.jpg   \n","...    ...        ...     ...                             ...   \n","23700   99          0       1  20170120221920654.jpg.chip.jpg   \n","23701   99          1       1  20170120134639935.jpg.chip.jpg   \n","23702   99          2       1  20170110182418864.jpg.chip.jpg   \n","23703   99          2       1  20170117195405372.jpg.chip.jpg   \n","23704   99          0       1  20170110182052119.jpg.chip.jpg   \n","\n","                                                  pixels  \n","0      129 128 128 126 127 130 133 135 139 142 145 14...  \n","1      164 74 111 168 169 171 175 182 184 188 193 199...  \n","2      67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n","3      193 197 198 200 199 200 202 203 204 205 208 21...  \n","4      202 205 209 210 209 209 210 211 212 214 218 21...  \n","...                                                  ...  \n","23700  127 100 94 81 77 77 74 99 102 98 128 145 160 1...  \n","23701  23 28 32 35 42 47 68 85 98 103 113 117 130 129...  \n","23702  59 50 37 40 34 19 30 101 156 170 177 184 187 1...  \n","23703  45 108 120 156 206 197 140 180 191 199 204 207...  \n","23704  156 161 160 165 170 173 166 177 183 191 187 18...  \n","\n","[23705 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-e45bb8e8-bf28-4064-ab99-f0c58ddf0142\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>ethnicity</th>\n","      <th>gender</th>\n","      <th>img_name</th>\n","      <th>pixels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161219203650636.jpg.chip.jpg</td>\n","      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161219222752047.jpg.chip.jpg</td>\n","      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161219222832191.jpg.chip.jpg</td>\n","      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161220144911423.jpg.chip.jpg</td>\n","      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161220144914327.jpg.chip.jpg</td>\n","      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23700</th>\n","      <td>99</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>20170120221920654.jpg.chip.jpg</td>\n","      <td>127 100 94 81 77 77 74 99 102 98 128 145 160 1...</td>\n","    </tr>\n","    <tr>\n","      <th>23701</th>\n","      <td>99</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>20170120134639935.jpg.chip.jpg</td>\n","      <td>23 28 32 35 42 47 68 85 98 103 113 117 130 129...</td>\n","    </tr>\n","    <tr>\n","      <th>23702</th>\n","      <td>99</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>20170110182418864.jpg.chip.jpg</td>\n","      <td>59 50 37 40 34 19 30 101 156 170 177 184 187 1...</td>\n","    </tr>\n","    <tr>\n","      <th>23703</th>\n","      <td>99</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>20170117195405372.jpg.chip.jpg</td>\n","      <td>45 108 120 156 206 197 140 180 191 199 204 207...</td>\n","    </tr>\n","    <tr>\n","      <th>23704</th>\n","      <td>99</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>20170110182052119.jpg.chip.jpg</td>\n","      <td>156 161 160 165 170 173 166 177 183 191 187 18...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23705 rows Ã— 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e45bb8e8-bf28-4064-ab99-f0c58ddf0142')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e45bb8e8-bf28-4064-ab99-f0c58ddf0142 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e45bb8e8-bf28-4064-ab99-f0c58ddf0142');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["df"],"id":"0e37fb3f-ae25-4f5f-8554-6d48aa3a375b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cddcf83d-be72-47f0-b94e-4b3cd09ea4fd"},"outputs":[],"source":["df[\"age\"] = pd.cut(df[\"age\"],bins=[0,3,18,45,64,116],labels=[\"0\",\"1\",\"2\",\"3\",\"4\"])"],"id":"cddcf83d-be72-47f0-b94e-4b3cd09ea4fd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"42bb38ec-6ede-435c-af7c-c56619577153","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1652043055345,"user_tz":-360,"elapsed":26,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}},"outputId":"eada93a3-d1ec-4baf-f80c-5f357a14d4ea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  age  ethnicity  gender                        img_name  \\\n","0   0          2       0  20161219203650636.jpg.chip.jpg   \n","1   0          2       0  20161219222752047.jpg.chip.jpg   \n","2   0          2       0  20161219222832191.jpg.chip.jpg   \n","3   0          2       0  20161220144911423.jpg.chip.jpg   \n","4   0          2       0  20161220144914327.jpg.chip.jpg   \n","\n","                                              pixels  \n","0  129 128 128 126 127 130 133 135 139 142 145 14...  \n","1  164 74 111 168 169 171 175 182 184 188 193 199...  \n","2  67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n","3  193 197 198 200 199 200 202 203 204 205 208 21...  \n","4  202 205 209 210 209 209 210 211 212 214 218 21...  "],"text/html":["\n","  <div id=\"df-90c56339-8251-4aad-bb72-fd847c78031c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>ethnicity</th>\n","      <th>gender</th>\n","      <th>img_name</th>\n","      <th>pixels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161219203650636.jpg.chip.jpg</td>\n","      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161219222752047.jpg.chip.jpg</td>\n","      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161219222832191.jpg.chip.jpg</td>\n","      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161220144911423.jpg.chip.jpg</td>\n","      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>20161220144914327.jpg.chip.jpg</td>\n","      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90c56339-8251-4aad-bb72-fd847c78031c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-90c56339-8251-4aad-bb72-fd847c78031c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-90c56339-8251-4aad-bb72-fd847c78031c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["df.head()"],"id":"42bb38ec-6ede-435c-af7c-c56619577153"},{"cell_type":"code","source":["len(df['age'].unique())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcrg8cJnIqjB","outputId":"b3c49ba6-988e-4719-eb2b-201fdbcc4ac7","executionInfo":{"status":"ok","timestamp":1652043055346,"user_tz":-360,"elapsed":23,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}}},"id":"tcrg8cJnIqjB","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2204797-af1f-471a-82e1-9dac4f29ffbc"},"outputs":[],"source":["x = df['pixels']\n","y = df[['age','ethnicity','gender','age']]"],"id":"c2204797-af1f-471a-82e1-9dac4f29ffbc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cf80c33-158b-4740-b366-072aec5b9893"},"outputs":[],"source":["new_x = []\n","for i, row in df.iterrows():\n","    l = row['pixels'].split(\" \")\n","    new_x.append(l)"],"id":"5cf80c33-158b-4740-b366-072aec5b9893"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ab2db70-6cbb-4df4-b6d3-a39dd3c43cf1"},"outputs":[],"source":["new_x =np.array(new_x)"],"id":"0ab2db70-6cbb-4df4-b6d3-a39dd3c43cf1"},{"cell_type":"code","source":["new_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRUGBZZjAt-P","executionInfo":{"status":"ok","timestamp":1652043072887,"user_tz":-360,"elapsed":35,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}},"outputId":"9b57beb6-5821-4172-bb2b-c26d7dbf4ada"},"id":"wRUGBZZjAt-P","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(23705, 2304)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["new_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8JFu0V_FOVo","executionInfo":{"status":"ok","timestamp":1652043072888,"user_tz":-360,"elapsed":33,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}},"outputId":"1579fe55-7d96-4ffd-bb05-a98d6705238f"},"id":"v8JFu0V_FOVo","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['129', '128', '128', ..., '146', '146', '146'],\n","       ['164', '74', '111', ..., '182', '170', '148'],\n","       ['67', '70', '71', ..., '112', '111', '108'],\n","       ...,\n","       ['59', '50', '37', ..., '98', '78', '78'],\n","       ['45', '108', '120', ..., '32', '35', '35'],\n","       ['156', '161', '160', ..., '190', '184', '174']], dtype='<U3')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a267e0cb-712a-420f-90f3-393f44446e2a"},"outputs":[],"source":["new_x=new_x.reshape(new_x.shape[0],48,48,1)"],"id":"a267e0cb-712a-420f-90f3-393f44446e2a"},{"cell_type":"code","source":["new_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOApAGstfUxk","executionInfo":{"status":"ok","timestamp":1652043072890,"user_tz":-360,"elapsed":13,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}},"outputId":"cd0ba2f9-a81e-476c-a82c-ff049c611f57"},"id":"kOApAGstfUxk","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(23705, 48, 48, 1)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ea804fa3-9744-40db-b858-7db2984270b9"},"outputs":[],"source":["new_x = np.array(new_x,'float64')"],"id":"ea804fa3-9744-40db-b858-7db2984270b9"},{"cell_type":"code","source":["new_x = new_x / 255.0\n","new_x = new_x / 255.0"],"metadata":{"id":"eSyuMVHIXoKV"},"id":"eSyuMVHIXoKV","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a37683a8-8ab2-4d10-9078-ccbfd04d7fb1"},"source":["### Creation a model"],"id":"a37683a8-8ab2-4d10-9078-ccbfd04d7fb1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0081aa9f-aaf3-465a-be75-69fd61636a75"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense , Activation , Dropout ,Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.metrics import categorical_accuracy\n","from keras.models import model_from_json\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import *\n","import tensorflow as tf"],"id":"0081aa9f-aaf3-465a-be75-69fd61636a75"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjGPcRMlT71C"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import itertools\n","import tensorflow as tf\n","import plotly.express as px\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, InputLayer\n","from tensorflow.keras.optimizers import RMSprop,Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy"],"id":"SjGPcRMlT71C"},{"cell_type":"code","source":["early_stopping = EarlyStopping(patience=10, \n","                               min_delta=0.001,\n","                               restore_best_weights=True)\n","\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                           patience = 2,\n","                                           verbose=1,\n","                                           factor=0.5,\n","                                           min_lr = 0.00001)"],"metadata":{"id":"oYWkv1zfYWs4"},"id":"oYWkv1zfYWs4","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b051e7b3-6667-453d-aa94-ca88423efb6f"},"outputs":[],"source":["gender=tf.keras.utils.to_categorical(y['gender'],num_classes=2)\n","ethnicity = tf.keras.utils.to_categorical(y['ethnicity'],num_classes=5)\n","age = tf.keras.utils.to_categorical(df['age'],num_classes=5)"],"id":"b051e7b3-6667-453d-aa94-ca88423efb6f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ew0q_vp9HX0N"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train_ethnicity, X_test_ethnicity, y_train_ethnicity, y_test_ethnicity = train_test_split(new_x, ethnicity, test_size= 0.3)\n","X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(new_x, gender, test_size= 0.3)\n","X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(new_x, age, test_size=0.3, random_state=42)\n","# X_train_age, X_test_age, y_train_age, y_test_age = train_test_split(x, age, test_size= 0.3)"],"id":"ew0q_vp9HX0N"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TO9U4j1sJJ1S"},"outputs":[],"source":["def my_model(num_classes, activation, loss):\n","    model = Sequential()\n","    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding = \"same\", input_shape=(48,48,1)))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv2D(64, kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Conv2D(64, kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\n","    model.add(BatchNormalization())\n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256,activation=\"relu\"))\n","    model.add(Dense(num_classes, activation=activation))\n","    \n","    model.compile(optimizer='Adam',\n","              loss= loss,\n","              metrics=['accuracy'])\n","    return model"],"id":"TO9U4j1sJJ1S"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":728},"id":"dl52KkL4S8YC","outputId":"545f78b9-339b-4217-a914-93c18b111552","executionInfo":{"status":"error","timestamp":1651584160242,"user_tz":-360,"elapsed":1897,"user":{"displayName":"Yrysbek Almakhan","userId":"09026504309854649983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-9b389cde3b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_ethnicity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m history_ethnicity = model_ethnicity.fit(X_train_ethnicity, y_train_ethnicity, batch_size=batch_size,\n\u001b[0;32m----> 5\u001b[0;31m                               epochs = epochs, validation_data = (X_test_ethnicity,y_test_ethnicity), steps_per_epoch= X_train_ethnicity.shape[0] // batch_size,callbacks= [early_stopping, learning_rate_reduction])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 48, 48, 1), found shape=(None, 2304)\n"]}],"source":["epochs = 200  # for better result increase the epochs\n","batch_size = 64\n","model_ethnicity = my_model(5,\"softmax\",'categorical_crossentropy')\n","history_ethnicity = model_ethnicity.fit(X_train_ethnicity, y_train_ethnicity, batch_size=batch_size,\n","                              epochs = epochs, validation_data = (X_test_ethnicity,y_test_ethnicity), steps_per_epoch= X_train_ethnicity.shape[0] // batch_size,callbacks= [early_stopping, learning_rate_reduction])"],"id":"dl52KkL4S8YC"},{"cell_type":"code","source":["epochs = 200  # for better result increase the epochs\n","batch_size = 64\n","loss, acc = model_ethnicity.evaluate(X_test_ethnicity, y_test_ethnicity, verbose=0)\n","print('Test loss: {}'.format(loss))\n","print('Test Accuracy: {}'.format(acc))\n","model_ethnicity.save(\"model.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"FXYb7FEnl0kV","outputId":"0b8538e4-b7c5-4d89-c3f6-44c56a9e79eb"},"id":"FXYb7FEnl0kV","execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-015f828e4272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m  \u001b[0;31m# for better result increase the epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ethnicity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_ethnicity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_ethnicity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["epochs = 200  # for better result increase the epochs\n","batch_size = 64\n","model_gender = my_model(2, \"sigmoid\", \"binary_crossentropy\")\n","history_gender = model_gender.fit(X_train_gender, y_train_gender, batch_size=batch_size,\n","                              epochs = epochs, validation_data = (X_test_gender,y_test_gender), steps_per_epoch= X_train_gender.shape[0] // batch_size, callbacks= [early_stopping, learning_rate_reduction])"],"metadata":{"id":"4mQxjYmre-QE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecc0f8b6-019a-4412-8df3-d026bfa2b1b2"},"id":"4mQxjYmre-QE","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","259/259 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.7736WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 107s 411ms/step - loss: 0.4845 - accuracy: 0.7736 - val_loss: 0.9014 - val_accuracy: 0.4850 - lr: 0.0010\n","Epoch 2/200\n","259/259 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8399WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 384ms/step - loss: 0.3511 - accuracy: 0.8399 - val_loss: 0.7331 - val_accuracy: 0.4989 - lr: 0.0010\n","Epoch 3/200\n","259/259 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8586WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 100s 387ms/step - loss: 0.3177 - accuracy: 0.8586 - val_loss: 0.5971 - val_accuracy: 0.6384 - lr: 0.0010\n","Epoch 4/200\n","259/259 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.8684WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 381ms/step - loss: 0.2932 - accuracy: 0.8684 - val_loss: 1.1226 - val_accuracy: 0.5332 - lr: 0.0010\n","Epoch 5/200\n","259/259 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.8821WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 383ms/step - loss: 0.2666 - accuracy: 0.8821 - val_loss: 0.8699 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 6/200\n","259/259 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.8941WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 381ms/step - loss: 0.2472 - accuracy: 0.8941 - val_loss: 0.9098 - val_accuracy: 0.5389 - lr: 0.0010\n","Epoch 7/200\n","259/259 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.9027WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 382ms/step - loss: 0.2272 - accuracy: 0.9027 - val_loss: 1.9316 - val_accuracy: 0.4855 - lr: 0.0010\n","Epoch 8/200\n","259/259 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9096WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 382ms/step - loss: 0.2152 - accuracy: 0.9096 - val_loss: 0.5072 - val_accuracy: 0.7530 - lr: 0.0010\n","Epoch 9/200\n","259/259 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9135WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 382ms/step - loss: 0.2060 - accuracy: 0.9135 - val_loss: 1.6740 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 10/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9212WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 382ms/step - loss: 0.1906 - accuracy: 0.9212 - val_loss: 1.7991 - val_accuracy: 0.5245 - lr: 0.0010\n","Epoch 11/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9289WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 383ms/step - loss: 0.1779 - accuracy: 0.9289 - val_loss: 2.3497 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 12/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9358WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 383ms/step - loss: 0.1580 - accuracy: 0.9358 - val_loss: 7.6934 - val_accuracy: 0.4850 - lr: 0.0010\n","Epoch 13/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9370WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 382ms/step - loss: 0.1591 - accuracy: 0.9370 - val_loss: 5.4007 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 14/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9424WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 382ms/step - loss: 0.1419 - accuracy: 0.9424 - val_loss: 5.0466 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 15/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9499WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 102s 392ms/step - loss: 0.1259 - accuracy: 0.9499 - val_loss: 0.7431 - val_accuracy: 0.5952 - lr: 0.0010\n","Epoch 16/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9523WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 383ms/step - loss: 0.1214 - accuracy: 0.9523 - val_loss: 4.1932 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 17/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9573WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 383ms/step - loss: 0.1100 - accuracy: 0.9573 - val_loss: 3.1356 - val_accuracy: 0.5150 - lr: 0.0010\n","Epoch 18/200\n","259/259 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9607WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","259/259 [==============================] - 99s 383ms/step - loss: 0.1022 - accuracy: 0.9607 - val_loss: 4.3149 - val_accuracy: 0.4850 - lr: 0.0010\n"]}]},{"cell_type":"code","source":["loss, acc = modtel_gender.evaluate(X_test_gender,y_test_gender, verbose=0)"],"metadata":{"id":"lX3Rhyx4qbcL"},"id":"lX3Rhyx4qbcL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9Dyf-bOy78C","outputId":"4b51d934-3b92-4115-a936-b5a26d83d910"},"id":"s9Dyf-bOy78C","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7529527544975281"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["model_gender.save(\"model_gender.h5\")"],"metadata":{"id":"FBluakpQy4Ca"},"id":"FBluakpQy4Ca","execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 200  # for better result increase the epochs\n","batch_size = 10\n","model_age = my_model(5,\"softmax\",'categorical_crossentropy')\n","history_age = model_age.fit(X_train_age, y_train_age, batch_size=batch_size,\n","                              epochs = epochs, validation_data = (X_test_age,y_test_age), \n","                            steps_per_epoch= X_train_age.shape[0] // batch_size, \n","                            callbacks= [early_stopping, \n","                            learning_rate_reduction])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NsSzCxRJbkZ","outputId":"11e9ac96-0bf3-43ee-8652-61615acb1e0d"},"id":"2NsSzCxRJbkZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.8867 - accuracy: 0.6657WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 143s 85ms/step - loss: 0.8867 - accuracy: 0.6657 - val_loss: 0.7267 - val_accuracy: 0.7129 - lr: 0.0010\n","Epoch 2/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7203WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 134s 81ms/step - loss: 0.7182 - accuracy: 0.7203 - val_loss: 2.1699 - val_accuracy: 0.1237 - lr: 0.0010\n","Epoch 3/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.7404WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 132s 80ms/step - loss: 0.6624 - accuracy: 0.7404 - val_loss: 1.7768 - val_accuracy: 0.1666 - lr: 0.0010\n","Epoch 4/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.7547WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 133s 80ms/step - loss: 0.6228 - accuracy: 0.7547 - val_loss: 2.5801 - val_accuracy: 0.1112 - lr: 0.0010\n","Epoch 5/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.5958 - accuracy: 0.7637WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 134s 81ms/step - loss: 0.5958 - accuracy: 0.7637 - val_loss: 6.3783 - val_accuracy: 0.4558 - lr: 0.0010\n","Epoch 6/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7723WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 134s 81ms/step - loss: 0.5673 - accuracy: 0.7723 - val_loss: 7.8963 - val_accuracy: 0.5783 - lr: 0.0010\n","Epoch 7/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.7859WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 131s 79ms/step - loss: 0.5508 - accuracy: 0.7859 - val_loss: 7.7575 - val_accuracy: 0.5782 - lr: 0.0010\n","Epoch 8/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7912WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 147s 89ms/step - loss: 0.5328 - accuracy: 0.7912 - val_loss: 14.9899 - val_accuracy: 0.5782 - lr: 0.0010\n","Epoch 9/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.8055WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 135s 81ms/step - loss: 0.4935 - accuracy: 0.8055 - val_loss: 21.2086 - val_accuracy: 0.5782 - lr: 0.0010\n","Epoch 10/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8114WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 135s 81ms/step - loss: 0.4723 - accuracy: 0.8114 - val_loss: 24.8269 - val_accuracy: 0.5782 - lr: 0.0010\n","Epoch 11/200\n","1659/1659 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8205WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","1659/1659 [==============================] - 132s 80ms/step - loss: 0.4476 - accuracy: 0.8205 - val_loss: 31.0283 - val_accuracy: 0.5782 - lr: 0.0010\n"]}]},{"cell_type":"code","source":["loss, acc = model_age.evaluate(X_test_age,y_test_age, verbose=0)"],"metadata":{"id":"wnQUtUYEYbx6"},"id":"wnQUtUYEYbx6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kUn7VpdYeva","outputId":"faf29ba3-c38d-4d55-80a8-5c56456b9b80"},"id":"9kUn7VpdYeva","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7128796577453613"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["model_age.save(\"model_age.h5\")"],"metadata":{"id":"wpPJgGWwtF4L"},"id":"wpPJgGWwtF4L","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Capstone.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}